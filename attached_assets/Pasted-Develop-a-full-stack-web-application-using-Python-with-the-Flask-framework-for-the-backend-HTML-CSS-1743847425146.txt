Develop a full-stack web application using Python with the Flask framework for the backend, HTML/CSS/JavaScript for a dynamic and responsive frontend, and SQLite as a lightweight, local database solution. The application must cater to two distinct user personas—faculty and students—offering tailored functionalities to support an academic essay evaluation workflow.
Core Objective:
Design and implement a platform that empowers faculty to author essay-style questions, complete with detailed parameters (question text, a reference 'key answer' for evaluation, a configurable word limit, and maximum marks), while enabling up to five students per question to submit their responses. Integrate the Gemini API to perform an automated, multi-dimensional evaluation of each student’s submission by comparing it to the key answer, assessing:  
Relevance: Alignment with the question’s intent and key answer’s focus.  

Coverage: Breadth and depth of content relative to the key answer.  

Structure and Clarity: Logical organization, coherence, and readability of the response.
Based on this evaluation, generate a numerical score for each submission and rank the students accordingly. Persist all data—questions, student responses, evaluation scores, and rankings—in a well-structured SQLite database for local storage and retrieval.
Key Features and Specifications:  
1. Faculty/Admin Interface:  
Authentication: Provide secure registration and login mechanisms for faculty, utilizing hashed passwords and session management.  

Question Creation: Enable faculty to compose new essay questions via an intuitive form, capturing:  
Question text (free-form, with rich text support).  

Key answer (a detailed reference response for evaluation).  

Word limit (enforceable constraint, e.g., 500 words).  

Maximum marks (e.g., out of 100).
Question Management: Display a paginated list of all created questions with options to view associated student submissions.  

Evaluation Trigger: Allow faculty to initiate the Gemini API-based evaluation process for submitted answers, retrieving scores and storing them in the database.  

Results Dashboard: Present a ranked leaderboard of student performances per question, including scores, names, and submission timestamps.  

PDF Export: Generate a polished, downloadable PDF report for each evaluated question, featuring:  
Student names, marks, and ranks.  

Submission timestamps.  

Institute branding (e.g., Jain University logo and name).  

A footer stating: 'This project is built by a student from Jain University' alongside Jain University’s logo and an additional institute logo (if provided).
2. Student Interface:  
Authentication: Offer a lightweight entry system—either full registration/login or a simplified name/email input option for submissions.  

Question Selection: Display an accessible, filterable list of available essay questions created by faculty, with metadata (e.g., word limit, max marks).  

Answer Submission: Provide a frontend form for students to submit responses, enforcing the word limit via real-time validation (e.g., a counter and cutoff mechanism).  

Post-Evaluation Feedback: After faculty triggers evaluation, allow students to view their individual scores, ranks, and optionally a brief breakdown of their performance (e.g., relevance, coverage, clarity) alongside peers’ rankings.
3. Evaluation Logic with Gemini API:
Integrate the Gemini API to perform a nuanced, automated comparison between student responses and the faculty-provided key answer. Structure the API prompt as follows to ensure precise and meaningful scoring:
'Given a reference answer [insert key answer] and a student’s response [insert submission], evaluate the submission on a scale of 0-100 based on three criteria: (1) Relevance to the question and alignment with the reference answer; (2) Coverage of key points and completeness relative to the reference; (3) Structure, coherence, and clarity of expression. Return a total score and a concise justification for each criterion.'
Parse the API’s response to extract scores and store them alongside the original submissions in SQLite.
Technical Expectations:  
Use Flask to handle routing, form validation, and API integration, ensuring RESTful design principles where applicable.  

Implement a responsive frontend with HTML/CSS/JavaScript, prioritizing usability (e.g., clean layouts, real-time feedback on word limits).  

Structure the SQLite database with normalized tables (e.g., users, questions, submissions, evaluations) to ensure data integrity and efficient querying.  

Provide clear documentation or inline comments explaining the evaluation workflow, database schema, and PDF generation process.  

Ensure scalability considerations (e.g., handling multiple questions and submissions gracefully) and basic error handling (e.g., API failures, invalid inputs).
Desired Output:
A detailed, step-by-step explanation of the application’s architecture, key code snippets for critical functionalities (e.g., Flask routes, Gemini API integration, SQLite queries, PDF generation), and suggestions for enhancing user experience or evaluation accuracy. The response should reflect a deep understanding of full-stack development, academic workflows, and API-driven automation, delivering actionable insights and a sophisticated solution.
